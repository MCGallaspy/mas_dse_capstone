{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydap.client\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "End_Year = 2019\n",
    "Start_Year = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dict = {}\n",
    "url_dict['Precip']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/pr/pr_'\n",
    "url_dict['Rhumiditymax']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/rmax/rmax_'\n",
    "url_dict['Rhumiditymin']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/rmin/rmin_'\n",
    "url_dict['Shumidit']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/sph/sph_'\n",
    "url_dict['Sradiation']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/srad/srad_'\n",
    "url_dict['WindFromDir']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/th/th_'\n",
    "url_dict['WindVelocity']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/vs/vs_'\n",
    "url_dict['Tempmax']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/tmmx/tmmx_'\n",
    "url_dict['Tempmin']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/tmmn/tmmn_'\n",
    "url_dict['BurningIndex']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/bi/bi_'\n",
    "url_dict['FuelMoist100']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/fm100/fm100_'\n",
    "url_dict['FuelMoist1000']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/fm1000/fm1000_'\n",
    "url_dict['EnergyRelease']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/erc/erc_'\n",
    "# url_dict['DroughtSeverity']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/pdsi/pdsi_'\n",
    "url_dict['EvapoTranspiration']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/etr/etr_'\n",
    "url_dict['EvapoTranspir_G']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/pet/pet_'\n",
    "url_dict['VaporPressDeficit']='http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/vpd/vpd_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url_part = 'http://thredds.northwestknowledge.net:8080/thredds/dodsC/MET/pr/pr_'\n",
    "url = base_url_part + str(End_Year) + '.nc'\n",
    "dataset = pydap.client.open_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((585,), (1386,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Slice the Bounding Box we wanted here.\n",
    "lon_ = dataset['lon']\n",
    "lon = lon_[:].data\n",
    "lat_ = dataset['lat']\n",
    "lat = lat_[:].data\n",
    "\n",
    "import numpy as np\n",
    "SD_county_lats = np.where((lat<33.6) & (lat>32.4))[0]\n",
    "SD_county_lons = np.where((lon<-116.0) & (lon>-118))[0]\n",
    "\n",
    "lat.shape, lon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 408, 163, 210)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_begin, lat_end = SD_county_lats[0], SD_county_lats[-1]\n",
    "lon_begin, lon_end = SD_county_lons[0], SD_county_lons[-1]\n",
    "lat_begin, lat_end, lon_begin, lon_end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "flag=0\n",
    "final_df = pd.DataFrame()\n",
    "for Year in tqdm(range(End_Year,Start_Year-1,-1)):\n",
    "    print(\"Downloading data for year {}\".format(Year))\n",
    "    url = base_url_part + str(Year) + '.nc'\n",
    "    dataset = pydap.client.open_url(url)\n",
    "    #Create the Base DataFrame with Days and Co-ordinates\n",
    "    days = pd.to_timedelta(dataset['day'].data[:], unit='days')\n",
    "    days = days + pd.to_datetime(\"19000101\", format=\"%Y%m%d\")\n",
    "    index = pd.MultiIndex.from_product([days.values,\n",
    "                                        lat[SD_county_lats].astype('f8'),\n",
    "                                        lon[SD_county_lons].astype('f8')],\n",
    "                                       names=['date', 'latitude', 'longitude'])\n",
    "    base_df = pd.DataFrame(index=index) \n",
    "    ##Load each Attriubute below\n",
    "    for item in tqdm(url_dict.values()):\n",
    "        print (\"Processing for\", item)\n",
    "        url = item + str(Year) + '.nc'\n",
    "#         print (url)\n",
    "        dataset = pydap.client.open_url(url)\n",
    "        for column in dataset.keys():\n",
    "            if column in ('lat', 'lon', 'crs', 'day'):\n",
    "                continue\n",
    "            #Here is where the Data Download happens\n",
    "            attrs = dataset[column].attributes\n",
    "            missing_value, scale, bias = attrs['missing_value'], attrs['scale_factor'], attrs['add_offset']\n",
    "            print(\"'{}': missing_values: {}, scale: {}, bias: {}\".format(column, missing_value, scale, bias))\n",
    "            raw_data = dataset[column][:, lat_begin:lat_end, lon_begin:lon_end]\n",
    "            base_date = pd.to_datetime(\"19000101\", format=\"%Y%m%d\")\n",
    "            values, days, lats, lons = raw_data.data\n",
    "            print(\"Data downloaded\")\n",
    "            days = base_date + pd.to_timedelta(days, unit=\"days\")\n",
    "            col_name = column + \"_\" + dataset[column].units\n",
    "            if item == 'Tempmax':\n",
    "                col_name = \"max_\" + col_name\n",
    "            elif item == 'Tempmin':\n",
    "                col_name = \"min_\" + col_name\n",
    "            values = values.astype('d')\n",
    "            values[values == missing_value] = np.nan\n",
    "            values = values * scale + bias\n",
    "            base_df.loc[(days, lats, lons), col_name] = values.ravel()\n",
    "    display(base_df.head(3))\n",
    "    final_df = pd.concat([final_df, base_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_df.to_parquet(\"gridMet.parquet.gz\", compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
