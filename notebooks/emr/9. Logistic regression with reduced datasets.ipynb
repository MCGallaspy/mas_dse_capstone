{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1589074996094_0002</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-17-24.ec2.internal:20888/proxy/application_1589074996094_0002/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-31-17.ec2.internal:8042/node/containerlogs/container_1589074996094_0002_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n",
      "6825410"
     ]
    }
   ],
   "source": [
    "s3_url = 's3a://dse-cohort5-group5/wildfire_capstone/integratedData.pca.parquet.gz'\n",
    "pca_df = spark.read.parquet(s3_url)\n",
    "pca_df.createOrReplaceTempView('pca')\n",
    "pca_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6826300"
     ]
    }
   ],
   "source": [
    "base_df = spark.read.parquet('s3a://dse-cohort5-group5/wildfire_capstone/integratedData.renamed.parquet.gz')\n",
    "base_df.createOrReplaceTempView(\"fire_occurrences\")\n",
    "base_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: long (nullable = true)\n",
      " |-- precipitation_amount_mm: double (nullable = true)\n",
      " |-- relative_humidity_%: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg: double (nullable = true)\n",
      " |-- surface_downwelling_shortwave_flux_in_air_W_m-2: double (nullable = true)\n",
      " |-- wind_from_direction_Degrees_Clockwise_from_north: double (nullable = true)\n",
      " |-- wind_speed_m/s: double (nullable = true)\n",
      " |-- max_air_temperature_K: double (nullable = true)\n",
      " |-- min_air_temperature_K: double (nullable = true)\n",
      " |-- burning_index_g_Unitless: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent: double (nullable = true)\n",
      " |-- energy_release_component-g_Unitless: double (nullable = true)\n",
      " |-- potential_evapotranspiration_mm: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa: double (nullable = true)\n",
      " |-- fire_occurred: integer (nullable = true)\n",
      " |-- acres_burned: double (nullable = true)\n",
      " |-- fire_name: string (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- __index_level_0__: long (nullable = true)"
     ]
    }
   ],
   "source": [
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_query = \"\"\"\n",
    "SELECT fire_occurrences.date,          fire_occurrences.latitude,     fire_occurrences.longitude,\n",
    "       fire_occurrences.fire_occurred, fire_occurrences.acres_burned, pca.pcaFeatures,\n",
    "       fire_occurrences.fire_name,\n",
    "       from_unixtime(cast(fire_occurrences.date/1e9 as long), 'yyyy') as year,\n",
    "       from_unixtime(cast(fire_occurrences.date/1e9 as long), 'MM') as month,\n",
    "       from_unixtime(cast(fire_occurrences.date/1e9 as long), 'dd') as day\n",
    "FROM fire_occurrences, pca\n",
    "WHERE pca.date      = fire_occurrences.date\n",
    "  AND pca.latitude  = fire_occurrences.latitude\n",
    "  AND pca.longitude = fire_occurrences.longitude\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "N_FEATURES_TO_KEEP = 40\n",
    "\n",
    "def to_array(col):\n",
    "    def to_array_(v):\n",
    "        return v.toArray().tolist()\n",
    "    # Important: asNondeterministic requires Spark 2.3 or later\n",
    "    # It can be safely removed i.e.\n",
    "    # return udf(to_array_, ArrayType(DoubleType()))(col)\n",
    "    # but at the cost of decreased performance\n",
    "    return udf(to_array_, ArrayType(DoubleType())).asNondeterministic()(col)\n",
    "\n",
    "joined_df = spark.sql(join_query)\n",
    "joined_df = joined_df.withColumn(\"pcaFeaturesArr\", to_array(col(\"pcaFeatures\")))\\\n",
    "                     .select([\"fire_occurrences.date\", \"fire_occurrences.latitude\", \"fire_occurrences.longitude\",\n",
    "                              \"fire_occurrences.fire_occurred\", \"fire_occurrences.acres_burned\",\n",
    "                              \"year\", \"month\", \"day\", \"fire_occurrences.fire_name\"]\n",
    "                             + [col(\"pcaFeaturesArr\")[i] for i in range(N_FEATURES_TO_KEEP)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6825410"
     ]
    }
   ],
   "source": [
    "joined_df.cache()\n",
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.createOrReplaceTempView(\"joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: long (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- fire_occurred: integer (nullable = true)\n",
      " |-- acres_burned: double (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- fire_name: string (nullable = true)\n",
      " |-- pcaFeaturesArr[0]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[1]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[2]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[3]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[4]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[5]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[6]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[7]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[8]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[9]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[10]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[11]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[12]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[13]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[14]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[15]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[16]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[17]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[18]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[19]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[20]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[21]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[22]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[23]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[24]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[25]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[26]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[27]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[28]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[29]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[30]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[31]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[32]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[33]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[34]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[35]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[36]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[37]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[38]: double (nullable = true)\n",
      " |-- pcaFeaturesArr[39]: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "def evaluate_weighted_logistic_regression(fires_weight=1, no_fires_weight=1):\n",
    "    # Add class weights for the Logistic Regression classifier below\n",
    "    with_fires_df_tmp = spark.sql(\"\"\"\n",
    "    SELECT *, row_number() OVER (PARTITION BY fire_name, year, month, day\n",
    "                                 ORDER BY     fire_name, year, month, day) AS rnum\n",
    "    FROM joined WHERE fire_occurred = 1\n",
    "    \"\"\")\n",
    "    with_fires_df_tmp.createOrReplaceTempView(\"with_fires_tmp\")\n",
    "    \n",
    "    with_fires_df = spark.sql(\"\"\"\n",
    "    SELECT *, {weight} as weight\n",
    "    FROM with_fires_tmp\n",
    "    WHERE rnum = 1\n",
    "    \"\"\".format(weight=fires_weight)).drop(\"rnum\")\n",
    "    \n",
    "    without_fires_df = spark.sql(\"\"\"\n",
    "    SELECT *, {weight} as weight\n",
    "    FROM joined\n",
    "    WHERE joined.fire_occurred = 0\n",
    "    \"\"\".format(pca_features=\", \".join(\"pcaFeaturesArr[{}]\".format(i) for i in range(0, 40)),\n",
    "               weight=no_fires_weight))\n",
    "    \n",
    "    with_fires_train,    with_fires_test    = with_fires_df.randomSplit([0.8, 0.2], seed=42)\n",
    "    without_fires_train, without_fires_test = without_fires_df.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    print(\"Training fires:\", len(with_fires_train.collect()))\n",
    "    print(\"Test fires:\", len(with_fires_test.collect()))\n",
    "    \n",
    "    train_df = with_fires_train.union(without_fires_train).sample(fraction=1.0, seed=42)\n",
    "    test_df  = with_fires_test.union(without_fires_test).sample(fraction=1.0, seed=42)\n",
    "    train_df.cache()\n",
    "    test_df.cache()\n",
    "    print(\"Train count, test count:\", train_df.count(), test_df.count())\n",
    "\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[\"pcaFeaturesArr[{}]\".format(i) for i in range(0, 40)],\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        featuresCol='features', \n",
    "        labelCol='fire_occurred',\n",
    "        weightCol='weight',\n",
    "        family=\"binomial\")\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "    model = pipeline.fit(train_df)\n",
    "\n",
    "    predictions = model.transform(test_df)\n",
    "    predictions.createOrReplaceTempView('predictions')\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"fire_occurred\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"f1\")\n",
    "\n",
    "    print(\"Test results for fire/no fire weights\", fires_weight, no_fires_weight)\n",
    "\n",
    "    f1 = evaluator.evaluate(predictions)\n",
    "    print(\"Test set f1 score = \" + str(f1))\n",
    "\n",
    "    true_positive = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 1 AND  prediction = 1\"\"\")\n",
    "    true_positive = true_positive.count()\n",
    "\n",
    "    false_negative = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 1 AND  prediction = 0\"\"\")\n",
    "    false_negative = false_negative.count()\n",
    "\n",
    "    true_negative = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 0 AND  prediction = 0\"\"\")\n",
    "    true_negative = true_negative.count()\n",
    "\n",
    "    false_positive = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 0 AND  prediction = 1\"\"\")\n",
    "    false_positive = false_positive.count()\n",
    "    \n",
    "    print(\"TP:\", true_positive)\n",
    "    print(\"FP:\", false_positive)\n",
    "    print(\"TN:\", true_negative)\n",
    "    print(\"FN:\", false_negative)\n",
    "\n",
    "    print(\"% precision for fires: {:%}\".format(true_positive/(true_positive + false_positive + 1e-3)))\n",
    "    print(\"% of fires recalled: {:%}\".format(true_positive/(true_positive + false_negative + 1e-3)))\n",
    "    print(\"Accuracy for non-fires: {:%}\".format(true_negative/(true_negative + false_positive + 1e-3)))\n",
    "    \n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fires: 331\n",
      "Test fires: 83\n",
      "Train count, test count: 5460075 1363582\n",
      "Test results for fire/no fire weights 1 1\n",
      "Test set f1 score = 0.9999086972863181\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 1363499\n",
      "FN: 83\n",
      "% precision for fires: 0.000000%\n",
      "% of fires recalled: 0.000000%\n",
      "Accuracy for non-fires: 100.000000%\n",
      "********************************************************************************\n",
      "Training fires: 331\n",
      "Test fires: 83\n",
      "Train count, test count: 5460075 1363582\n",
      "Test results for fire/no fire weights 1000 1\n",
      "Test set f1 score = 0.9983044338574267\n",
      "TP: 13\n",
      "FP: 4382\n",
      "TN: 1359117\n",
      "FN: 70\n",
      "% precision for fires: 0.295791%\n",
      "% of fires recalled: 15.662462%\n",
      "Accuracy for non-fires: 99.678621%\n",
      "********************************************************************************\n",
      "Training fires: 331\n",
      "Test fires: 83\n",
      "Train count, test count: 5460075 1363582\n",
      "Test results for fire/no fire weights 10000 1\n",
      "Test set f1 score = 0.907733948712437\n",
      "TP: 66\n",
      "FP: 230215\n",
      "TN: 1133284\n",
      "FN: 17\n",
      "% precision for fires: 0.028661%\n",
      "% of fires recalled: 79.517114%\n",
      "Accuracy for non-fires: 83.115866%\n",
      "********************************************************************************\n",
      "Training fires: 331\n",
      "Test fires: 83\n",
      "Train count, test count: 5460075 1363582\n",
      "Test results for fire/no fire weights 100000 1\n",
      "Test set f1 score = 0.6817466607259903\n",
      "TP: 81\n",
      "FP: 658287\n",
      "TN: 705212\n",
      "FN: 2\n",
      "% precision for fires: 0.012303%\n",
      "% of fires recalled: 97.589186%\n",
      "Accuracy for non-fires: 51.720757%\n",
      "********************************************************************************\n",
      "Training fires: 331\n",
      "Test fires: 83\n",
      "Train count, test count: 5460075 1363582\n",
      "Test results for fire/no fire weights 1000000 1\n",
      "Test set f1 score = 0.5150441549431428\n",
      "TP: 82\n",
      "FP: 890542\n",
      "TN: 472957\n",
      "FN: 1\n",
      "% precision for fires: 0.009207%\n",
      "% of fires recalled: 98.793990%\n",
      "Accuracy for non-fires: 34.687007%\n",
      "********************************************************************************"
     ]
    }
   ],
   "source": [
    "for n in [0, 3, 4, 5, 6]:\n",
    "    evaluate_weighted_logistic_regression(10**n, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "def evaluate_weighted_logistic_regression_random_fires(fires_weight=1, no_fires_weight=1):\n",
    "    # Add class weights for the Logistic Regression classifier below\n",
    "    # Use the same number of fire rows as above, but select randomly\n",
    "    with_fires_df = spark.sql(\"\"\"\n",
    "    SELECT *, {weight} as weight, rand(42) as rnd\n",
    "    FROM joined\n",
    "    WHERE joined.fire_occurred = 1\n",
    "    ORDER BY rnd\n",
    "    LIMIT 133\n",
    "    \"\"\".format(weight=fires_weight)).drop(\"rnd\")\n",
    "    \n",
    "    without_fires_df = spark.sql(\"\"\"\n",
    "    SELECT *, {weight} as weight\n",
    "    FROM joined\n",
    "    WHERE joined.fire_occurred = 0\n",
    "    \"\"\".format(pca_features=\", \".join(\"pcaFeaturesArr[{}]\".format(i) for i in range(0, 40)),\n",
    "               weight=no_fires_weight))\n",
    "    \n",
    "    # Had to adjust random split numbers to get closer to first split, for some reason I can't determine\n",
    "    with_fires_train,    with_fires_test    = with_fires_df.randomSplit([0.7, 0.3], seed=42)\n",
    "    without_fires_train, without_fires_test = without_fires_df.randomSplit([0.8, 0.2], seed=42)\n",
    "    \n",
    "    print(\"Training fires:\", len(with_fires_train.collect()))\n",
    "    print(\"Test fires:\", len(with_fires_test.collect()))\n",
    "    \n",
    "    train_df = with_fires_train.union(without_fires_train).sample(fraction=1.0, seed=42)\n",
    "    test_df  = with_fires_test.union(without_fires_test).sample(fraction=1.0, seed=42)\n",
    "    train_df.cache()\n",
    "    test_df.cache()\n",
    "    print(\"Train count, test count:\", train_df.count(), test_df.count())\n",
    "\n",
    "\n",
    "    assembler = VectorAssembler(\n",
    "        inputCols=[\"pcaFeaturesArr[{}]\".format(i) for i in range(0, 40)],\n",
    "        outputCol=\"features\")\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        featuresCol='features', \n",
    "        labelCol='fire_occurred',\n",
    "        weightCol='weight',\n",
    "        family=\"binomial\")\n",
    "\n",
    "    pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "    model = pipeline.fit(train_df)\n",
    "\n",
    "    predictions = model.transform(test_df)\n",
    "    predictions.createOrReplaceTempView('predictions')\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"fire_occurred\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"f1\")\n",
    "\n",
    "    print(\"Test results for fire/no fire weights\", fires_weight, no_fires_weight)\n",
    "\n",
    "    f1 = evaluator.evaluate(predictions)\n",
    "    print(\"Test set f1 score = \" + str(f1))\n",
    "\n",
    "    true_positive = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 1 AND  prediction = 1\"\"\")\n",
    "    true_positive = true_positive.count()\n",
    "\n",
    "    false_negative = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 1 AND  prediction = 0\"\"\")\n",
    "    false_negative = false_negative.count()\n",
    "\n",
    "    true_negative = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 0 AND  prediction = 0\"\"\")\n",
    "    true_negative = true_negative.count()\n",
    "\n",
    "    false_positive = spark.sql(\"\"\"\n",
    "    SELECT * FROM predictions WHERE fire_occurred = 0 AND  prediction = 1\"\"\")\n",
    "    false_positive = false_positive.count()\n",
    "    \n",
    "    print(\"TP:\", true_positive)\n",
    "    print(\"FP:\", false_positive)\n",
    "    print(\"TN:\", true_negative)\n",
    "    print(\"FN:\", false_negative)\n",
    "    \n",
    "    print(\"% precision for fires: {:%}\".format(true_positive/(true_positive + false_positive + 1e-3)))\n",
    "    print(\"% of fires recalled: {:%}\".format(true_positive/(true_positive + false_negative + 1e-3)))\n",
    "    print(\"Accuracy for non-fires: {:%}\".format(true_negative/(true_negative + false_positive + 1e-3)))\n",
    "    \n",
    "    print(\"*\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fires: 104\n",
      "Test fires: 29\n",
      "Train count, test count: 5459848 1363528\n",
      "Test results for fire/no fire weights 1 1\n",
      "Test set f1 score = 0.9999680975778988\n",
      "TP: 0\n",
      "FP: 0\n",
      "TN: 1363499\n",
      "FN: 29\n",
      "% precision for fires: 0.000000%\n",
      "% of fires recalled: 0.000000%\n",
      "Accuracy for non-fires: 100.000000%\n",
      "********************************************************************************\n",
      "Training fires: 104\n",
      "Test fires: 29\n",
      "Train count, test count: 5459848 1363528\n",
      "Test results for fire/no fire weights 1000 1\n",
      "Test set f1 score = 0.9992479408186572\n",
      "TP: 9\n",
      "FP: 1972\n",
      "TN: 1361527\n",
      "FN: 20\n",
      "% precision for fires: 0.454316%\n",
      "% of fires recalled: 31.033413%\n",
      "Accuracy for non-fires: 99.855372%\n",
      "********************************************************************************\n",
      "Training fires: 104\n",
      "Test fires: 29\n",
      "Train count, test count: 5459848 1363528\n",
      "Test results for fire/no fire weights 10000 1\n",
      "Test set f1 score = 0.9833462956040537\n",
      "TP: 15\n",
      "FP: 44602\n",
      "TN: 1318897\n",
      "FN: 14\n",
      "% precision for fires: 0.033619%\n",
      "% of fires recalled: 51.722354%\n",
      "Accuracy for non-fires: 96.728857%\n",
      "********************************************************************************\n",
      "Training fires: 104\n",
      "Test fires: 29\n",
      "Train count, test count: 5459848 1363528\n",
      "Test results for fire/no fire weights 100000 1\n",
      "Test set f1 score = 0.9041324417375649\n",
      "TP: 22\n",
      "FP: 238511\n",
      "TN: 1124988\n",
      "FN: 7\n",
      "% precision for fires: 0.009223%\n",
      "% of fires recalled: 75.859453%\n",
      "Accuracy for non-fires: 82.507431%\n",
      "********************************************************************************\n",
      "Training fires: 104\n",
      "Test fires: 29\n",
      "Train count, test count: 5459848 1363528\n",
      "Test results for fire/no fire weights 1000000 1\n",
      "Test set f1 score = 0.8472447329068669\n",
      "TP: 26\n",
      "FP: 361324\n",
      "TN: 1002175\n",
      "FN: 3\n",
      "% precision for fires: 0.007195%\n",
      "% of fires recalled: 89.652081%\n",
      "Accuracy for non-fires: 73.500237%\n",
      "********************************************************************************"
     ]
    }
   ],
   "source": [
    "for n in [0, 3, 4, 5, 6]:\n",
    "    evaluate_weighted_logistic_regression_random_fires(10**n, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
