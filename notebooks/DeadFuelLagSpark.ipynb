{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "spark = SparkSession.builder.appName('DeadFuelLag')\\\n",
    ".config(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc1\")\\\n",
    ".config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmlspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_parquet('gridMet.parquet.gz')\n",
    "# #df[\"surface_downwelling_shortwave_flux_in_air_W_m-2\"] = df[\"surface_downwelling_shortwave_flux_in_air_W m-2\"]\n",
    "# #del df[\"surface_downwelling_shortwave_flux_in_air_W m-2\"]\n",
    "# df[\"wind_from_direction_Degrees_Clockwise_from_north\"] = df[\"wind_from_direction_Degrees Clockwise_from_north\"]\n",
    "# del df[\"wind_from_direction_Degrees Clockwise_from_north\"]\n",
    "# df.to_parquet('gridMet.parquet.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(\"gridMet.parquet.gz\").where(F.col(\"precipitation_amount_mm\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- precipitation_amount_mm: double (nullable = true)\n",
      " |-- relative_humidity_%: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg: double (nullable = true)\n",
      " |-- wind_speed_m/s: double (nullable = true)\n",
      " |-- max_air_temperature_K: double (nullable = true)\n",
      " |-- min_air_temperature_K: double (nullable = true)\n",
      " |-- burning_index_g_Unitless: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent: double (nullable = true)\n",
      " |-- energy_release_component-g_Unitless: double (nullable = true)\n",
      " |-- potential_evapotranspiration_mm: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa: double (nullable = true)\n",
      " |-- surface_downwelling_shortwave_flux_in_air_W_m-2: double (nullable = true)\n",
      " |-- wind_from_direction_Degrees_Clockwise_from_north: double (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(F.col(\"latitude\"), F.col(\"longitude\")).orderBy(F.col(\"date\").desc())\n",
    "df = df.withColumnRenamed(\"surface_downwelling_shortwave_flux_in_air_W_m-2\",\"surface_downwelling_shortwave_flux_in_air_W m-2\")\n",
    "df = df.withColumn(\"cumLag\", F.lit(0))\n",
    "for i in range(1,8):\n",
    "    df = df.withColumn(\"lag-\"+str(i),F.col(\"dead_fuel_moisture_1000hr_Percent\")- F.lag(F.col(\"dead_fuel_moisture_1000hr_Percent\"), i).over(windowSpec))\n",
    "    df = df.withColumn(\"cumLag\", F.when((F.col(\"lag-\"+str(i))<= 0) & (F.col(\"cumLag\") == i-1), i ).otherwise(F.col(\"cumLag\")))\n",
    "df = df.withColumn(\"lag-Test\",F.lag(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AggFunctions(df, cols):\n",
    "    for idx, col in enumerate(cols):\n",
    "        df = df.withColumn(col+\"_mean_7_days\", F.avg(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-7,0)))\n",
    "        df = df.withColumn(col+\"_mean_14_days\", F.avg(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-14,0)))\n",
    "        df = df.withColumn(col+\"_mean_30_days\", F.avg(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-30,0)))\n",
    "        df = df.withColumn(col+\"_mean_6_months\", F.avg(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-182,0)))\n",
    "        df = df.withColumn(col+\"_mean_1_year\", F.avg(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-365,0)))\n",
    "        \n",
    "        df = df.withColumn(col+\"_max_7_days\", F.max(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-7,0)))\n",
    "        df = df.withColumn(col+\"_max_14_days\", F.max(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-14,0)))\n",
    "        df = df.withColumn(col+\"_max_30_days\", F.max(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-30,0)))\n",
    "        df = df.withColumn(col+\"_max_6_months\", F.max(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-182,0)))\n",
    "        df = df.withColumn(col+\"_max_1_year\", F.max(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-365,0)))\n",
    "    return df\n",
    "        \n",
    "agg_cols = ['mean_vapor_pressure_deficit_kPa','relative_humidity_%',\n",
    "                                             'specific_humidity_kg/kg','wind_speed_m/s','max_air_temperature_K',\n",
    "                                             'dead_fuel_moisture_100hr_Percent','dead_fuel_moisture_1000hr_Percent']\n",
    "df = AggFunctions(df,agg_cols)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"movingAvg\",F.avg(F.col(\"dead_fuel_moisture_1000hr_Percent\")).over(windowSpec.rowsBetween(-7,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(precipitation_amount_mm=0.0, relative_humidity_%=27.200000000000003, specific_humidity_kg/kg=0.005090000000000001, wind_speed_m/s=1.8, max_air_temperature_K=292.6, min_air_temperature_K=274.2, burning_index_g_Unitless=17.0, dead_fuel_moisture_100hr_Percent=19.1, dead_fuel_moisture_1000hr_Percent=22.1, energy_release_component-g_Unitless=19.0, potential_evapotranspiration_mm=1.7000000000000002, mean_vapor_pressure_deficit_kPa=0.67, surface_downwelling_shortwave_flux_in_air_W m-2=121.4, wind_from_direction_Degrees_Clockwise_from_north=92.0, date=datetime.datetime(2019, 12, 30, 16, 0), latitude=33.025000000000006, longitude=-116.97499996666667, cumLag=0, lag-1=None, lag-2=None, lag-3=None, lag-4=None, lag-5=None, lag-6=None, lag-7=None, lag-Test=None, movingAvg=22.1, mean_vapor_pressure_deficit_kPa_mean_7_days=22.1, mean_vapor_pressure_deficit_kPa_mean_14_days=22.1, mean_vapor_pressure_deficit_kPa_mean_30_days=22.1, mean_vapor_pressure_deficit_kPa_mean_6_months=22.1, mean_vapor_pressure_deficit_kPa_mean_1_year=22.1, mean_vapor_pressure_deficit_kPa_max_7_days=22.1, mean_vapor_pressure_deficit_kPa_max_14_days=22.1, mean_vapor_pressure_deficit_kPa_max_30_days=22.1, mean_vapor_pressure_deficit_kPa_max_6_months=22.1, mean_vapor_pressure_deficit_kPa_max_1_year=22.1, relative_humidity_%_mean_7_days=22.1, relative_humidity_%_mean_14_days=22.1, relative_humidity_%_mean_30_days=22.1, relative_humidity_%_mean_6_months=22.1, relative_humidity_%_mean_1_year=22.1, relative_humidity_%_max_7_days=22.1, relative_humidity_%_max_14_days=22.1, relative_humidity_%_max_30_days=22.1, relative_humidity_%_max_6_months=22.1, relative_humidity_%_max_1_year=22.1, specific_humidity_kg/kg_mean_7_days=22.1, specific_humidity_kg/kg_mean_14_days=22.1, specific_humidity_kg/kg_mean_30_days=22.1, specific_humidity_kg/kg_mean_6_months=22.1, specific_humidity_kg/kg_mean_1_year=22.1, specific_humidity_kg/kg_max_7_days=22.1, specific_humidity_kg/kg_max_14_days=22.1, specific_humidity_kg/kg_max_30_days=22.1, specific_humidity_kg/kg_max_6_months=22.1, specific_humidity_kg/kg_max_1_year=22.1, wind_speed_m/s_mean_7_days=22.1, wind_speed_m/s_mean_14_days=22.1, wind_speed_m/s_mean_30_days=22.1, wind_speed_m/s_mean_6_months=22.1, wind_speed_m/s_mean_1_year=22.1, wind_speed_m/s_max_7_days=22.1, wind_speed_m/s_max_14_days=22.1, wind_speed_m/s_max_30_days=22.1, wind_speed_m/s_max_6_months=22.1, wind_speed_m/s_max_1_year=22.1, max_air_temperature_K_mean_7_days=22.1, max_air_temperature_K_mean_14_days=22.1, max_air_temperature_K_mean_30_days=22.1, max_air_temperature_K_mean_6_months=22.1, max_air_temperature_K_mean_1_year=22.1, max_air_temperature_K_max_7_days=22.1, max_air_temperature_K_max_14_days=22.1, max_air_temperature_K_max_30_days=22.1, max_air_temperature_K_max_6_months=22.1, max_air_temperature_K_max_1_year=22.1, dead_fuel_moisture_100hr_Percent_mean_7_days=22.1, dead_fuel_moisture_100hr_Percent_mean_14_days=22.1, dead_fuel_moisture_100hr_Percent_mean_30_days=22.1, dead_fuel_moisture_100hr_Percent_mean_6_months=22.1, dead_fuel_moisture_100hr_Percent_mean_1_year=22.1, dead_fuel_moisture_100hr_Percent_max_7_days=22.1, dead_fuel_moisture_100hr_Percent_max_14_days=22.1, dead_fuel_moisture_100hr_Percent_max_30_days=22.1, dead_fuel_moisture_100hr_Percent_max_6_months=22.1, dead_fuel_moisture_100hr_Percent_max_1_year=22.1, dead_fuel_moisture_1000hr_Percent_mean_7_days=22.1, dead_fuel_moisture_1000hr_Percent_mean_14_days=22.1, dead_fuel_moisture_1000hr_Percent_mean_30_days=22.1, dead_fuel_moisture_1000hr_Percent_mean_6_months=22.1, dead_fuel_moisture_1000hr_Percent_mean_1_year=22.1, dead_fuel_moisture_1000hr_Percent_max_7_days=22.1, dead_fuel_moisture_1000hr_Percent_max_14_days=22.1, dead_fuel_moisture_1000hr_Percent_max_30_days=22.1, dead_fuel_moisture_1000hr_Percent_max_6_months=22.1, dead_fuel_moisture_1000hr_Percent_max_1_year=22.1),\n",
       " Row(precipitation_amount_mm=0.0, relative_humidity_%=52.900000000000006, specific_humidity_kg/kg=0.005960000000000001, wind_speed_m/s=2.6, max_air_temperature_K=286.8, min_air_temperature_K=279.9, burning_index_g_Unitless=16.0, dead_fuel_moisture_100hr_Percent=19.5, dead_fuel_moisture_1000hr_Percent=22.200000000000003, energy_release_component-g_Unitless=16.0, potential_evapotranspiration_mm=1.4000000000000001, mean_vapor_pressure_deficit_kPa=0.35000000000000003, surface_downwelling_shortwave_flux_in_air_W m-2=107.9, wind_from_direction_Degrees_Clockwise_from_north=81.0, date=datetime.datetime(2019, 12, 29, 16, 0), latitude=33.025000000000006, longitude=-116.97499996666667, cumLag=0, lag-1=0.10000000000000142, lag-2=None, lag-3=None, lag-4=None, lag-5=None, lag-6=None, lag-7=None, lag-Test=22.1, movingAvg=22.150000000000002, mean_vapor_pressure_deficit_kPa_mean_7_days=22.150000000000002, mean_vapor_pressure_deficit_kPa_mean_14_days=22.150000000000002, mean_vapor_pressure_deficit_kPa_mean_30_days=22.150000000000002, mean_vapor_pressure_deficit_kPa_mean_6_months=22.150000000000002, mean_vapor_pressure_deficit_kPa_mean_1_year=22.150000000000002, mean_vapor_pressure_deficit_kPa_max_7_days=22.200000000000003, mean_vapor_pressure_deficit_kPa_max_14_days=22.200000000000003, mean_vapor_pressure_deficit_kPa_max_30_days=22.200000000000003, mean_vapor_pressure_deficit_kPa_max_6_months=22.200000000000003, mean_vapor_pressure_deficit_kPa_max_1_year=22.200000000000003, relative_humidity_%_mean_7_days=22.150000000000002, relative_humidity_%_mean_14_days=22.150000000000002, relative_humidity_%_mean_30_days=22.150000000000002, relative_humidity_%_mean_6_months=22.150000000000002, relative_humidity_%_mean_1_year=22.150000000000002, relative_humidity_%_max_7_days=22.200000000000003, relative_humidity_%_max_14_days=22.200000000000003, relative_humidity_%_max_30_days=22.200000000000003, relative_humidity_%_max_6_months=22.200000000000003, relative_humidity_%_max_1_year=22.200000000000003, specific_humidity_kg/kg_mean_7_days=22.150000000000002, specific_humidity_kg/kg_mean_14_days=22.150000000000002, specific_humidity_kg/kg_mean_30_days=22.150000000000002, specific_humidity_kg/kg_mean_6_months=22.150000000000002, specific_humidity_kg/kg_mean_1_year=22.150000000000002, specific_humidity_kg/kg_max_7_days=22.200000000000003, specific_humidity_kg/kg_max_14_days=22.200000000000003, specific_humidity_kg/kg_max_30_days=22.200000000000003, specific_humidity_kg/kg_max_6_months=22.200000000000003, specific_humidity_kg/kg_max_1_year=22.200000000000003, wind_speed_m/s_mean_7_days=22.150000000000002, wind_speed_m/s_mean_14_days=22.150000000000002, wind_speed_m/s_mean_30_days=22.150000000000002, wind_speed_m/s_mean_6_months=22.150000000000002, wind_speed_m/s_mean_1_year=22.150000000000002, wind_speed_m/s_max_7_days=22.200000000000003, wind_speed_m/s_max_14_days=22.200000000000003, wind_speed_m/s_max_30_days=22.200000000000003, wind_speed_m/s_max_6_months=22.200000000000003, wind_speed_m/s_max_1_year=22.200000000000003, max_air_temperature_K_mean_7_days=22.150000000000002, max_air_temperature_K_mean_14_days=22.150000000000002, max_air_temperature_K_mean_30_days=22.150000000000002, max_air_temperature_K_mean_6_months=22.150000000000002, max_air_temperature_K_mean_1_year=22.150000000000002, max_air_temperature_K_max_7_days=22.200000000000003, max_air_temperature_K_max_14_days=22.200000000000003, max_air_temperature_K_max_30_days=22.200000000000003, max_air_temperature_K_max_6_months=22.200000000000003, max_air_temperature_K_max_1_year=22.200000000000003, dead_fuel_moisture_100hr_Percent_mean_7_days=22.150000000000002, dead_fuel_moisture_100hr_Percent_mean_14_days=22.150000000000002, dead_fuel_moisture_100hr_Percent_mean_30_days=22.150000000000002, dead_fuel_moisture_100hr_Percent_mean_6_months=22.150000000000002, dead_fuel_moisture_100hr_Percent_mean_1_year=22.150000000000002, dead_fuel_moisture_100hr_Percent_max_7_days=22.200000000000003, dead_fuel_moisture_100hr_Percent_max_14_days=22.200000000000003, dead_fuel_moisture_100hr_Percent_max_30_days=22.200000000000003, dead_fuel_moisture_100hr_Percent_max_6_months=22.200000000000003, dead_fuel_moisture_100hr_Percent_max_1_year=22.200000000000003, dead_fuel_moisture_1000hr_Percent_mean_7_days=22.150000000000002, dead_fuel_moisture_1000hr_Percent_mean_14_days=22.150000000000002, dead_fuel_moisture_1000hr_Percent_mean_30_days=22.150000000000002, dead_fuel_moisture_1000hr_Percent_mean_6_months=22.150000000000002, dead_fuel_moisture_1000hr_Percent_mean_1_year=22.150000000000002, dead_fuel_moisture_1000hr_Percent_max_7_days=22.200000000000003, dead_fuel_moisture_1000hr_Percent_max_14_days=22.200000000000003, dead_fuel_moisture_1000hr_Percent_max_30_days=22.200000000000003, dead_fuel_moisture_1000hr_Percent_max_6_months=22.200000000000003, dead_fuel_moisture_1000hr_Percent_max_1_year=22.200000000000003),\n",
       " Row(precipitation_amount_mm=0.0, relative_humidity_%=36.6, specific_humidity_kg/kg=0.005180000000000001, wind_speed_m/s=2.2, max_air_temperature_K=289.3, min_air_temperature_K=275.6, burning_index_g_Unitless=16.0, dead_fuel_moisture_100hr_Percent=20.8, dead_fuel_moisture_1000hr_Percent=22.5, energy_release_component-g_Unitless=16.0, potential_evapotranspiration_mm=1.5, mean_vapor_pressure_deficit_kPa=0.48, surface_downwelling_shortwave_flux_in_air_W m-2=117.30000000000001, wind_from_direction_Degrees_Clockwise_from_north=127.0, date=datetime.datetime(2019, 12, 28, 16, 0), latitude=33.025000000000006, longitude=-116.97499996666667, cumLag=0, lag-1=0.29999999999999716, lag-2=0.3999999999999986, lag-3=None, lag-4=None, lag-5=None, lag-6=None, lag-7=None, lag-Test=22.200000000000003, movingAvg=22.26666666666667, mean_vapor_pressure_deficit_kPa_mean_7_days=22.26666666666667, mean_vapor_pressure_deficit_kPa_mean_14_days=22.26666666666667, mean_vapor_pressure_deficit_kPa_mean_30_days=22.26666666666667, mean_vapor_pressure_deficit_kPa_mean_6_months=22.26666666666667, mean_vapor_pressure_deficit_kPa_mean_1_year=22.26666666666667, mean_vapor_pressure_deficit_kPa_max_7_days=22.5, mean_vapor_pressure_deficit_kPa_max_14_days=22.5, mean_vapor_pressure_deficit_kPa_max_30_days=22.5, mean_vapor_pressure_deficit_kPa_max_6_months=22.5, mean_vapor_pressure_deficit_kPa_max_1_year=22.5, relative_humidity_%_mean_7_days=22.26666666666667, relative_humidity_%_mean_14_days=22.26666666666667, relative_humidity_%_mean_30_days=22.26666666666667, relative_humidity_%_mean_6_months=22.26666666666667, relative_humidity_%_mean_1_year=22.26666666666667, relative_humidity_%_max_7_days=22.5, relative_humidity_%_max_14_days=22.5, relative_humidity_%_max_30_days=22.5, relative_humidity_%_max_6_months=22.5, relative_humidity_%_max_1_year=22.5, specific_humidity_kg/kg_mean_7_days=22.26666666666667, specific_humidity_kg/kg_mean_14_days=22.26666666666667, specific_humidity_kg/kg_mean_30_days=22.26666666666667, specific_humidity_kg/kg_mean_6_months=22.26666666666667, specific_humidity_kg/kg_mean_1_year=22.26666666666667, specific_humidity_kg/kg_max_7_days=22.5, specific_humidity_kg/kg_max_14_days=22.5, specific_humidity_kg/kg_max_30_days=22.5, specific_humidity_kg/kg_max_6_months=22.5, specific_humidity_kg/kg_max_1_year=22.5, wind_speed_m/s_mean_7_days=22.26666666666667, wind_speed_m/s_mean_14_days=22.26666666666667, wind_speed_m/s_mean_30_days=22.26666666666667, wind_speed_m/s_mean_6_months=22.26666666666667, wind_speed_m/s_mean_1_year=22.26666666666667, wind_speed_m/s_max_7_days=22.5, wind_speed_m/s_max_14_days=22.5, wind_speed_m/s_max_30_days=22.5, wind_speed_m/s_max_6_months=22.5, wind_speed_m/s_max_1_year=22.5, max_air_temperature_K_mean_7_days=22.26666666666667, max_air_temperature_K_mean_14_days=22.26666666666667, max_air_temperature_K_mean_30_days=22.26666666666667, max_air_temperature_K_mean_6_months=22.26666666666667, max_air_temperature_K_mean_1_year=22.26666666666667, max_air_temperature_K_max_7_days=22.5, max_air_temperature_K_max_14_days=22.5, max_air_temperature_K_max_30_days=22.5, max_air_temperature_K_max_6_months=22.5, max_air_temperature_K_max_1_year=22.5, dead_fuel_moisture_100hr_Percent_mean_7_days=22.26666666666667, dead_fuel_moisture_100hr_Percent_mean_14_days=22.26666666666667, dead_fuel_moisture_100hr_Percent_mean_30_days=22.26666666666667, dead_fuel_moisture_100hr_Percent_mean_6_months=22.26666666666667, dead_fuel_moisture_100hr_Percent_mean_1_year=22.26666666666667, dead_fuel_moisture_100hr_Percent_max_7_days=22.5, dead_fuel_moisture_100hr_Percent_max_14_days=22.5, dead_fuel_moisture_100hr_Percent_max_30_days=22.5, dead_fuel_moisture_100hr_Percent_max_6_months=22.5, dead_fuel_moisture_100hr_Percent_max_1_year=22.5, dead_fuel_moisture_1000hr_Percent_mean_7_days=22.26666666666667, dead_fuel_moisture_1000hr_Percent_mean_14_days=22.26666666666667, dead_fuel_moisture_1000hr_Percent_mean_30_days=22.26666666666667, dead_fuel_moisture_1000hr_Percent_mean_6_months=22.26666666666667, dead_fuel_moisture_1000hr_Percent_mean_1_year=22.26666666666667, dead_fuel_moisture_1000hr_Percent_max_7_days=22.5, dead_fuel_moisture_1000hr_Percent_max_14_days=22.5, dead_fuel_moisture_1000hr_Percent_max_30_days=22.5, dead_fuel_moisture_1000hr_Percent_max_6_months=22.5, dead_fuel_moisture_1000hr_Percent_max_1_year=22.5),\n",
       " Row(precipitation_amount_mm=0.0, relative_humidity_%=38.900000000000006, specific_humidity_kg/kg=0.0049700000000000005, wind_speed_m/s=1.7000000000000002, max_air_temperature_K=287.9, min_air_temperature_K=275.2, burning_index_g_Unitless=15.0, dead_fuel_moisture_100hr_Percent=21.700000000000003, dead_fuel_moisture_1000hr_Percent=22.700000000000003, energy_release_component-g_Unitless=15.0, potential_evapotranspiration_mm=1.3, mean_vapor_pressure_deficit_kPa=0.42, surface_downwelling_shortwave_flux_in_air_W m-2=144.4, wind_from_direction_Degrees_Clockwise_from_north=237.0, date=datetime.datetime(2019, 12, 27, 16, 0), latitude=33.025000000000006, longitude=-116.97499996666667, cumLag=0, lag-1=0.20000000000000284, lag-2=0.5, lag-3=0.6000000000000014, lag-4=None, lag-5=None, lag-6=None, lag-7=None, lag-Test=22.5, movingAvg=22.375000000000004, mean_vapor_pressure_deficit_kPa_mean_7_days=22.375000000000004, mean_vapor_pressure_deficit_kPa_mean_14_days=22.375000000000004, mean_vapor_pressure_deficit_kPa_mean_30_days=22.375000000000004, mean_vapor_pressure_deficit_kPa_mean_6_months=22.375000000000004, mean_vapor_pressure_deficit_kPa_mean_1_year=22.375000000000004, mean_vapor_pressure_deficit_kPa_max_7_days=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_14_days=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_30_days=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_6_months=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_1_year=22.700000000000003, relative_humidity_%_mean_7_days=22.375000000000004, relative_humidity_%_mean_14_days=22.375000000000004, relative_humidity_%_mean_30_days=22.375000000000004, relative_humidity_%_mean_6_months=22.375000000000004, relative_humidity_%_mean_1_year=22.375000000000004, relative_humidity_%_max_7_days=22.700000000000003, relative_humidity_%_max_14_days=22.700000000000003, relative_humidity_%_max_30_days=22.700000000000003, relative_humidity_%_max_6_months=22.700000000000003, relative_humidity_%_max_1_year=22.700000000000003, specific_humidity_kg/kg_mean_7_days=22.375000000000004, specific_humidity_kg/kg_mean_14_days=22.375000000000004, specific_humidity_kg/kg_mean_30_days=22.375000000000004, specific_humidity_kg/kg_mean_6_months=22.375000000000004, specific_humidity_kg/kg_mean_1_year=22.375000000000004, specific_humidity_kg/kg_max_7_days=22.700000000000003, specific_humidity_kg/kg_max_14_days=22.700000000000003, specific_humidity_kg/kg_max_30_days=22.700000000000003, specific_humidity_kg/kg_max_6_months=22.700000000000003, specific_humidity_kg/kg_max_1_year=22.700000000000003, wind_speed_m/s_mean_7_days=22.375000000000004, wind_speed_m/s_mean_14_days=22.375000000000004, wind_speed_m/s_mean_30_days=22.375000000000004, wind_speed_m/s_mean_6_months=22.375000000000004, wind_speed_m/s_mean_1_year=22.375000000000004, wind_speed_m/s_max_7_days=22.700000000000003, wind_speed_m/s_max_14_days=22.700000000000003, wind_speed_m/s_max_30_days=22.700000000000003, wind_speed_m/s_max_6_months=22.700000000000003, wind_speed_m/s_max_1_year=22.700000000000003, max_air_temperature_K_mean_7_days=22.375000000000004, max_air_temperature_K_mean_14_days=22.375000000000004, max_air_temperature_K_mean_30_days=22.375000000000004, max_air_temperature_K_mean_6_months=22.375000000000004, max_air_temperature_K_mean_1_year=22.375000000000004, max_air_temperature_K_max_7_days=22.700000000000003, max_air_temperature_K_max_14_days=22.700000000000003, max_air_temperature_K_max_30_days=22.700000000000003, max_air_temperature_K_max_6_months=22.700000000000003, max_air_temperature_K_max_1_year=22.700000000000003, dead_fuel_moisture_100hr_Percent_mean_7_days=22.375000000000004, dead_fuel_moisture_100hr_Percent_mean_14_days=22.375000000000004, dead_fuel_moisture_100hr_Percent_mean_30_days=22.375000000000004, dead_fuel_moisture_100hr_Percent_mean_6_months=22.375000000000004, dead_fuel_moisture_100hr_Percent_mean_1_year=22.375000000000004, dead_fuel_moisture_100hr_Percent_max_7_days=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_14_days=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_30_days=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_6_months=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_1_year=22.700000000000003, dead_fuel_moisture_1000hr_Percent_mean_7_days=22.375000000000004, dead_fuel_moisture_1000hr_Percent_mean_14_days=22.375000000000004, dead_fuel_moisture_1000hr_Percent_mean_30_days=22.375000000000004, dead_fuel_moisture_1000hr_Percent_mean_6_months=22.375000000000004, dead_fuel_moisture_1000hr_Percent_mean_1_year=22.375000000000004, dead_fuel_moisture_1000hr_Percent_max_7_days=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_14_days=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_30_days=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_6_months=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_1_year=22.700000000000003),\n",
       " Row(precipitation_amount_mm=0.0, relative_humidity_%=48.1, specific_humidity_kg/kg=0.00561, wind_speed_m/s=2.8000000000000003, max_air_temperature_K=287.1, min_air_temperature_K=275.2, burning_index_g_Unitless=16.0, dead_fuel_moisture_100hr_Percent=22.8, dead_fuel_moisture_1000hr_Percent=22.5, energy_release_component-g_Unitless=14.0, potential_evapotranspiration_mm=1.3, mean_vapor_pressure_deficit_kPa=0.28, surface_downwelling_shortwave_flux_in_air_W m-2=138.8, wind_from_direction_Degrees_Clockwise_from_north=320.0, date=datetime.datetime(2019, 12, 26, 16, 0), latitude=33.025000000000006, longitude=-116.97499996666667, cumLag=2, lag-1=-0.20000000000000284, lag-2=0.0, lag-3=0.29999999999999716, lag-4=0.3999999999999986, lag-5=None, lag-6=None, lag-7=None, lag-Test=22.700000000000003, movingAvg=22.400000000000002, mean_vapor_pressure_deficit_kPa_mean_7_days=22.400000000000002, mean_vapor_pressure_deficit_kPa_mean_14_days=22.400000000000002, mean_vapor_pressure_deficit_kPa_mean_30_days=22.400000000000002, mean_vapor_pressure_deficit_kPa_mean_6_months=22.400000000000002, mean_vapor_pressure_deficit_kPa_mean_1_year=22.400000000000002, mean_vapor_pressure_deficit_kPa_max_7_days=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_14_days=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_30_days=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_6_months=22.700000000000003, mean_vapor_pressure_deficit_kPa_max_1_year=22.700000000000003, relative_humidity_%_mean_7_days=22.400000000000002, relative_humidity_%_mean_14_days=22.400000000000002, relative_humidity_%_mean_30_days=22.400000000000002, relative_humidity_%_mean_6_months=22.400000000000002, relative_humidity_%_mean_1_year=22.400000000000002, relative_humidity_%_max_7_days=22.700000000000003, relative_humidity_%_max_14_days=22.700000000000003, relative_humidity_%_max_30_days=22.700000000000003, relative_humidity_%_max_6_months=22.700000000000003, relative_humidity_%_max_1_year=22.700000000000003, specific_humidity_kg/kg_mean_7_days=22.400000000000002, specific_humidity_kg/kg_mean_14_days=22.400000000000002, specific_humidity_kg/kg_mean_30_days=22.400000000000002, specific_humidity_kg/kg_mean_6_months=22.400000000000002, specific_humidity_kg/kg_mean_1_year=22.400000000000002, specific_humidity_kg/kg_max_7_days=22.700000000000003, specific_humidity_kg/kg_max_14_days=22.700000000000003, specific_humidity_kg/kg_max_30_days=22.700000000000003, specific_humidity_kg/kg_max_6_months=22.700000000000003, specific_humidity_kg/kg_max_1_year=22.700000000000003, wind_speed_m/s_mean_7_days=22.400000000000002, wind_speed_m/s_mean_14_days=22.400000000000002, wind_speed_m/s_mean_30_days=22.400000000000002, wind_speed_m/s_mean_6_months=22.400000000000002, wind_speed_m/s_mean_1_year=22.400000000000002, wind_speed_m/s_max_7_days=22.700000000000003, wind_speed_m/s_max_14_days=22.700000000000003, wind_speed_m/s_max_30_days=22.700000000000003, wind_speed_m/s_max_6_months=22.700000000000003, wind_speed_m/s_max_1_year=22.700000000000003, max_air_temperature_K_mean_7_days=22.400000000000002, max_air_temperature_K_mean_14_days=22.400000000000002, max_air_temperature_K_mean_30_days=22.400000000000002, max_air_temperature_K_mean_6_months=22.400000000000002, max_air_temperature_K_mean_1_year=22.400000000000002, max_air_temperature_K_max_7_days=22.700000000000003, max_air_temperature_K_max_14_days=22.700000000000003, max_air_temperature_K_max_30_days=22.700000000000003, max_air_temperature_K_max_6_months=22.700000000000003, max_air_temperature_K_max_1_year=22.700000000000003, dead_fuel_moisture_100hr_Percent_mean_7_days=22.400000000000002, dead_fuel_moisture_100hr_Percent_mean_14_days=22.400000000000002, dead_fuel_moisture_100hr_Percent_mean_30_days=22.400000000000002, dead_fuel_moisture_100hr_Percent_mean_6_months=22.400000000000002, dead_fuel_moisture_100hr_Percent_mean_1_year=22.400000000000002, dead_fuel_moisture_100hr_Percent_max_7_days=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_14_days=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_30_days=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_6_months=22.700000000000003, dead_fuel_moisture_100hr_Percent_max_1_year=22.700000000000003, dead_fuel_moisture_1000hr_Percent_mean_7_days=22.400000000000002, dead_fuel_moisture_1000hr_Percent_mean_14_days=22.400000000000002, dead_fuel_moisture_1000hr_Percent_mean_30_days=22.400000000000002, dead_fuel_moisture_1000hr_Percent_mean_6_months=22.400000000000002, dead_fuel_moisture_1000hr_Percent_mean_1_year=22.400000000000002, dead_fuel_moisture_1000hr_Percent_max_7_days=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_14_days=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_30_days=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_6_months=22.700000000000003, dead_fuel_moisture_1000hr_Percent_max_1_year=22.700000000000003)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- precipitation_amount_mm: double (nullable = true)\n",
      " |-- relative_humidity_%: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg: double (nullable = true)\n",
      " |-- wind_speed_m/s: double (nullable = true)\n",
      " |-- max_air_temperature_K: double (nullable = true)\n",
      " |-- min_air_temperature_K: double (nullable = true)\n",
      " |-- burning_index_g_Unitless: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent: double (nullable = true)\n",
      " |-- energy_release_component-g_Unitless: double (nullable = true)\n",
      " |-- potential_evapotranspiration_mm: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa: double (nullable = true)\n",
      " |-- surface_downwelling_shortwave_flux_in_air_W m-2: double (nullable = true)\n",
      " |-- wind_from_direction_Degrees_Clockwise_from_north: double (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- cumLag: integer (nullable = false)\n",
      " |-- lag-1: double (nullable = true)\n",
      " |-- lag-2: double (nullable = true)\n",
      " |-- lag-3: double (nullable = true)\n",
      " |-- lag-4: double (nullable = true)\n",
      " |-- lag-5: double (nullable = true)\n",
      " |-- lag-6: double (nullable = true)\n",
      " |-- lag-7: double (nullable = true)\n",
      " |-- lag-Test: double (nullable = true)\n",
      " |-- movingAvg: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_mean_7_days: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_mean_14_days: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_mean_30_days: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_mean_6_months: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_mean_1_year: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_max_7_days: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_max_14_days: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_max_30_days: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_max_6_months: double (nullable = true)\n",
      " |-- mean_vapor_pressure_deficit_kPa_max_1_year: double (nullable = true)\n",
      " |-- relative_humidity_%_mean_7_days: double (nullable = true)\n",
      " |-- relative_humidity_%_mean_14_days: double (nullable = true)\n",
      " |-- relative_humidity_%_mean_30_days: double (nullable = true)\n",
      " |-- relative_humidity_%_mean_6_months: double (nullable = true)\n",
      " |-- relative_humidity_%_mean_1_year: double (nullable = true)\n",
      " |-- relative_humidity_%_max_7_days: double (nullable = true)\n",
      " |-- relative_humidity_%_max_14_days: double (nullable = true)\n",
      " |-- relative_humidity_%_max_30_days: double (nullable = true)\n",
      " |-- relative_humidity_%_max_6_months: double (nullable = true)\n",
      " |-- relative_humidity_%_max_1_year: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_mean_7_days: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_mean_14_days: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_mean_30_days: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_mean_6_months: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_mean_1_year: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_max_7_days: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_max_14_days: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_max_30_days: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_max_6_months: double (nullable = true)\n",
      " |-- specific_humidity_kg/kg_max_1_year: double (nullable = true)\n",
      " |-- wind_speed_m/s_mean_7_days: double (nullable = true)\n",
      " |-- wind_speed_m/s_mean_14_days: double (nullable = true)\n",
      " |-- wind_speed_m/s_mean_30_days: double (nullable = true)\n",
      " |-- wind_speed_m/s_mean_6_months: double (nullable = true)\n",
      " |-- wind_speed_m/s_mean_1_year: double (nullable = true)\n",
      " |-- wind_speed_m/s_max_7_days: double (nullable = true)\n",
      " |-- wind_speed_m/s_max_14_days: double (nullable = true)\n",
      " |-- wind_speed_m/s_max_30_days: double (nullable = true)\n",
      " |-- wind_speed_m/s_max_6_months: double (nullable = true)\n",
      " |-- wind_speed_m/s_max_1_year: double (nullable = true)\n",
      " |-- max_air_temperature_K_mean_7_days: double (nullable = true)\n",
      " |-- max_air_temperature_K_mean_14_days: double (nullable = true)\n",
      " |-- max_air_temperature_K_mean_30_days: double (nullable = true)\n",
      " |-- max_air_temperature_K_mean_6_months: double (nullable = true)\n",
      " |-- max_air_temperature_K_mean_1_year: double (nullable = true)\n",
      " |-- max_air_temperature_K_max_7_days: double (nullable = true)\n",
      " |-- max_air_temperature_K_max_14_days: double (nullable = true)\n",
      " |-- max_air_temperature_K_max_30_days: double (nullable = true)\n",
      " |-- max_air_temperature_K_max_6_months: double (nullable = true)\n",
      " |-- max_air_temperature_K_max_1_year: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_mean_7_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_mean_14_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_mean_30_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_mean_6_months: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_mean_1_year: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_max_7_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_max_14_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_max_30_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_max_6_months: double (nullable = true)\n",
      " |-- dead_fuel_moisture_100hr_Percent_max_1_year: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_mean_7_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_mean_14_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_mean_30_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_mean_6_months: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_mean_1_year: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_max_7_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_max_14_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_max_30_days: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_max_6_months: double (nullable = true)\n",
      " |-- dead_fuel_moisture_1000hr_Percent_max_1_year: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    " 'precipitation_amount_mm',\n",
    " 'relative_humidity_%',\n",
    " 'specific_humidity_kg/kg',\n",
    " 'surface_downwelling_shortwave_flux_in_air_W m-2',\n",
    " 'wind_from_direction_Degrees_Clockwise_from_north',\n",
    " 'wind_speed_m/s',\n",
    " 'max_air_temperature_K',\n",
    " 'min_air_temperature_K',\n",
    " 'burning_index_g_Unitless',\n",
    " 'dead_fuel_moisture_100hr_Percent',\n",
    " 'dead_fuel_moisture_1000hr_Percent',\n",
    " 'energy_release_component-g_Unitless',\n",
    " 'potential_evapotranspiration_mm',\n",
    " 'mean_vapor_pressure_deficit_kPa',\n",
    " 'cumLag'\n",
    "]\n",
    "assembler = VectorAssembler(\n",
    "    inputCols= features,\n",
    "    outputCol='features'\n",
    ")\n",
    "train_df = df.withColumn(\"label\", F.rand().cast(\"int\"))\n",
    "train_df = assembler.transform(train_df)\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o383.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 238, localhost, executor driver): org.apache.spark.memory.SparkOutOfMemoryError: Unable to acquire 16384 bytes of memory, got 0\r\n\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:157)\r\n\tat org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:98)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter.<init>(UnsafeInMemorySorter.java:128)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.<init>(UnsafeExternalSorter.java:161)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.create(UnsafeExternalSorter.java:128)\r\n\tat org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.add(ExternalAppendOnlyUnsafeRowArray.scala:115)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextPartition(WindowExec.scala:343)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:369)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextRow(WindowExec.scala:314)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.<init>(WindowExec.scala:323)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:302)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)\r\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.translate(TrainUtils.scala:229)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:385)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:188)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:185)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1080)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1062)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$reduce$1.apply(Dataset.scala:1643)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$withNewRDDExecutionId$1.apply(Dataset.scala:3355)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3351)\r\n\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1642)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$class.innerTrain(LightGBMBase.scala:150)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMRegressor.innerTrain(LightGBMRegressor.scala:38)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$class.train(LightGBMBase.scala:40)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMRegressor.train(LightGBMRegressor.scala:38)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMRegressor.train(LightGBMRegressor.scala:38)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.memory.SparkOutOfMemoryError: Unable to acquire 16384 bytes of memory, got 0\r\n\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:157)\r\n\tat org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:98)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter.<init>(UnsafeInMemorySorter.java:128)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.<init>(UnsafeExternalSorter.java:161)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.create(UnsafeExternalSorter.java:128)\r\n\tat org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.add(ExternalAppendOnlyUnsafeRowArray.scala:115)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextPartition(WindowExec.scala:343)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:369)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextRow(WindowExec.scala:314)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.<init>(WindowExec.scala:323)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:302)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)\r\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.translate(TrainUtils.scala:229)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:385)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:188)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:185)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-17e966a8ece8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                           \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                           \u001b[0mlearningRate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                           numLeaves=31).fit(train_df)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \"\"\"\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o383.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 238, localhost, executor driver): org.apache.spark.memory.SparkOutOfMemoryError: Unable to acquire 16384 bytes of memory, got 0\r\n\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:157)\r\n\tat org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:98)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter.<init>(UnsafeInMemorySorter.java:128)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.<init>(UnsafeExternalSorter.java:161)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.create(UnsafeExternalSorter.java:128)\r\n\tat org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.add(ExternalAppendOnlyUnsafeRowArray.scala:115)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextPartition(WindowExec.scala:343)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:369)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextRow(WindowExec.scala:314)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.<init>(WindowExec.scala:323)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:302)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)\r\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.translate(TrainUtils.scala:229)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:385)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:188)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:185)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2112)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1080)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.reduce(RDD.scala:1062)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$reduce$1.apply(Dataset.scala:1643)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$withNewRDDExecutionId$1.apply(Dataset.scala:3355)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\r\n\tat org.apache.spark.sql.Dataset.withNewRDDExecutionId(Dataset.scala:3351)\r\n\tat org.apache.spark.sql.Dataset.reduce(Dataset.scala:1642)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$class.innerTrain(LightGBMBase.scala:150)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMRegressor.innerTrain(LightGBMRegressor.scala:38)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$class.train(LightGBMBase.scala:40)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMRegressor.train(LightGBMRegressor.scala:38)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMRegressor.train(LightGBMRegressor.scala:38)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\nCaused by: org.apache.spark.memory.SparkOutOfMemoryError: Unable to acquire 16384 bytes of memory, got 0\r\n\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:157)\r\n\tat org.apache.spark.memory.MemoryConsumer.allocateArray(MemoryConsumer.java:98)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeInMemorySorter.<init>(UnsafeInMemorySorter.java:128)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.<init>(UnsafeExternalSorter.java:161)\r\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.create(UnsafeExternalSorter.java:128)\r\n\tat org.apache.spark.sql.execution.ExternalAppendOnlyUnsafeRowArray.add(ExternalAppendOnlyUnsafeRowArray.scala:115)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextPartition(WindowExec.scala:343)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:369)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.next(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage9.processNext(Unknown Source)\r\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\r\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.fetchNextRow(WindowExec.scala:314)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11$$anon$1.<init>(WindowExec.scala:323)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:303)\r\n\tat org.apache.spark.sql.execution.window.WindowExec$$anonfun$11.apply(WindowExec.scala:302)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:100)\r\n\tat org.apache.spark.rdd.CoalescedRDD$$anonfun$compute$1.apply(CoalescedRDD.scala:99)\r\n\tat scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435)\r\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\r\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\r\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\r\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\r\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\r\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\r\n\tat scala.collection.AbstractIterator.to(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\r\n\tat scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334)\r\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\r\n\tat scala.collection.AbstractIterator.toArray(Iterator.scala:1334)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.translate(TrainUtils.scala:229)\r\n\tat com.microsoft.ml.spark.lightgbm.TrainUtils$.trainLightGBM(TrainUtils.scala:385)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat com.microsoft.ml.spark.lightgbm.LightGBMBase$$anonfun$6.apply(LightGBMBase.scala:145)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:188)\r\n\tat org.apache.spark.sql.execution.MapPartitionsExec$$anonfun$5.apply(objects.scala:185)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.sql.execution.SQLExecutionRDD.compute(SQLExecutionRDD.scala:55)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\r\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)\r\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:310)\r\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "## TODO see if mmlspark works on EMR\n",
    "# from mmlspark.lightgbm import LightGBMRegressor\n",
    "# model = LightGBMRegressor(objective='quantile',\n",
    "#                           alpha=0.2,\n",
    "#                           learningRate=0.3,\n",
    "#                           numLeaves=31).fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
